# old version of ESD

def fast_esd(ifgs, overlap, crop_overlap=True):
    """Applies an in-place phase correction to burst (complex) interferograms to mitigate phase jumps between the bursts.
    Args:
        ifgs (list): List of complex SLC interferograms
        overlap (int): Number of overlapping azimuth pixels between two bursts (can be computed with `compute_burst_overlap`)

    Notes:
        Based on ideas introduced in:
        Qin, Y.; Perissin, D.; Bai, J. A Common “Stripmap-Like” Interferometric Processing Chain for TOPS and ScanSAR Wide Swath Mode. Remote Sens. 2018, 10, 1504.

    """

    import matplotlib.pyplot as plt

    if len(ifgs) < 2:
        raise ValueError(
            "There must be at least 2 consecutive bursts from the same subsawths."
        )

    nodataval = np.nan + 1j * np.nan
    phase_diffs = []
    for i in range(len(ifgs) - 1):
        log.info(f"Compute cross interferogram {i+1} / {len(ifgs) - 1}")
        cross = ifgs[i][-overlap:] * ifgs[i + 1][:overlap].conj()
        phi_clx = cross[~np.isnan(cross)]
        phase_diffs.append(np.angle(phi_clx.mean()))

    # phi_max_esd = np.concatenate(phase_diffs).mean()

    naz, nrg = ifgs[0].shape
    x = np.arange(naz)
    xdown, xup = overlap / 2, naz - 1 - overlap / 2

    def make_ramp(idx):
        if idx == 0:
            ydown, yup = -phase_diffs[idx] / 2, phase_diffs[idx] / 2
        elif idx == len(ifgs) - 1:
            ydown, yup = -phase_diffs[idx - 1] / 2, phase_diffs[idx - 1] / 2
        else:
            ydown, yup = -phase_diffs[idx - 1] / 2, phase_diffs[idx] / 2
        slope = (yup - ydown) / (xup - xdown)
        off = ydown - slope * xdown
        ramp = slope * x + off
        return np.exp(-1j * (ramp[:, None] + np.zeros((nrg))))

    # old version, keeping for comparison
    # dphi = np.angle(phi_max_esd)
    # y1 = dphi * (1 - overlap / (naz-1))

    # ramp = np.linspace(-y1, y1, naz)
    # ramp = dphi * np.arange(naz) / (naz - 1 - overlap)
    # ramp = dphi * np.linspace(-(naz-1)/2, (naz-1)/2, naz) / (naz - 1 - overlap)

    # esd_ramp = np.exp(1j * (ramp[:, None] + np.zeros((nrg))))

    # TODO: improve by downweighting points far from mid overlap ?
    naz, nrg = ifgs[0].shape
    for i, ifg in enumerate(ifgs):
        log.info(f"Apply ESD to interferogram {i+1} / {len(ifgs)}")
        esd_ramp = make_ramp(i).astype(np.complex64)
        ifg *= esd_ramp
        if crop_overlap:
            if i > 0:
                ifg[: int(overlap / 2) + 1] = nodataval
            if i < len(ifgs) - 1:
                ifg[-int(overlap / 2) - 1 :] = nodataval

# resampling functions using remap (commented)
# not using because float32 is not accurate enough for resampling
# if opencv adds the relative coordinate parameter this could be an option

def align(arr_mst, arr_slv, az, rg, order=3):
    log.info("Warp slave to master geometry.")

    if np.iscomplexobj(arr_slv):
        nodata_dst = np.nan + 1j * np.nan
    else:
        nodata_dst = np.nan

    if np.iscomplexobj(arr_mst):
        nodata_src = np.nan + 1j * np.nan
    else:
        nodata_src = np.nan

    # keep this code for potential speedup
    # pitfall: absolute coordinates are not accurate in float32
    # TODO: find if relative coordinates could be used!
    # if np.iscomplexobj(arr_slv):
    #     arr_out = remap(
    #         arr_slv.real.astype(np.float32),
    #         rg.astype(np.float32),
    #         az.astype(np.float32),
    #         4,
    #     ) + 1j * remap(
    #         arr_slv.imag.astype(np.float32),
    #         rg.astype(np.float32),
    #         az.astype(np.float32),
    #         4,
    #     )
    # else:
    #     arr_out = remap(
    #         arr_slv.astype(np.float32), rg.astype(np.float32), az.astype(np.float32), 4
    #     )

    msk_dst = arr_slv != nodata_dst
    msk_src = arr_mst != nodata_src
    arr_out = np.full_like(arr_mst, dtype=arr_slv.dtype, fill_value=nodata_dst)
    msk_out = np.zeros_like(msk_src, dtype=bool)
    coords = np.vstack((az[msk_src], rg[msk_src]))
    arr_out[msk_src] = map_coordinates(
        arr_slv,
        coords,
        order=order,
        prefilter=False,
    )
    msk_out[msk_src] = map_coordinates(
        msk_dst,
        coords,
        order=0,
    )
    arr_out[~msk_out] = np.nan
    return arr_out.reshape(arr_mst.shape)
    # return arr_out


# TODO: auto-upsampling factor, rename, mask nan in coordinates, no mask resampling
def resample(arr, file_dem, file_out, az, rg, order=3, write_phase=False):

    # replace nan to work with map_coordinates
    # TODO: use finite NaN values, i.e -9999
    if np.iscomplexobj(arr):
        nodataval = 0.0 + 1j * 0.0
    else:
        nodataval = 0
    msk = arr == nodataval

    # retrieve dem profile
    with rasterio.open(file_dem) as ds_dem:
        out_prof = ds_dem.profile.copy()

    # TODO: avoid mask warping
    log.info("Warp to match DEM geometry")

    width = az.shape[1]
    height = az.shape[0]
    wped = np.zeros_like(rg, dtype=arr.dtype)
    msk_re = np.zeros_like(rg, dtype=msk.dtype)
    valid = (az != np.nan) & (rg != np.nan)
    wped[valid] = map_coordinates(arr, (az[valid], rg[valid]), order=order)
    msk_re[valid] = map_coordinates(msk, (az[valid], rg[valid]), order=0)

    wped[~valid] = nodataval
    wped[msk_re] = nodataval
    wped = wped.reshape(height, width)

    # keep this code for potential speedup
    # pitfall: absolute coordinates are not accurate in float32
    # however this is less problematic in geocoding than coregistration
    # if np.iscomplexobj(arr):
    #     wped = remap(
    #         arr.real.astype(np.float32), rg.astype(np.float32), az.astype(np.float32), 4
    #     ) + 1j * remap(
    #         arr.imag.astype(np.float32), rg.astype(np.float32), az.astype(np.float32), 4
    #     )
    # else:
    #     wped = remap(
    #         arr.astype(np.float32), rg.astype(np.float32), az.astype(np.float32), 4
    #     )

    # TODO: enforce COG
    log.info("Write output GeoTIFF")
    if write_phase:
        phi = np.angle(wped)
        # phi = np.angle(arr_out)
        # TODO: change nodata
        out_prof.update({"dtype": phi.dtype, "count": 1, "nodata": 0})
        with rasterio.open(file_out, "w", **out_prof) as dst:
            dst.write(phi, 1)
    else:
        # TODO: change nodata
        out_prof.update({"dtype": arr.dtype, "count": 1, "nodata": 0})
        with rasterio.open(file_out, "w", **out_prof) as dst:
            dst.write(wped, 1)


# attempt at using xarray to create intermediate data
# writing netcdf either results in too large files or takes too much time (zip compression too slow)

naz = prm.lines_per_burst
nrg = prm.samples_per_burst

nburst = prm.burst_count

burst_min = 1
burst_max = 3
burst_coords = [f"burst_{n}" for n in range(burst_min, burst_max + 1)]
time_coords = [prm.start_time, sec.start_time]


log.info("Creating raster dataset")
real_da = xr.DataArray(
    np.zeros((2, len(burst_coords), naz, nrg), dtype="float32"),
    dims=("time", "burst", "az", "rg"),
    coords={
        "time": time_coords,
        "burst": burst_coords,
        "az": np.arange(naz),
        "rg": np.arange(nrg),
    },
)
imag_da = xr.DataArray(
    np.zeros((2, len(burst_coords), naz, nrg), dtype="float32"),
    dims=("time", "burst", "az", "rg"),
    coords={
        "time": time_coords,
        "burst": burst_coords,
        "az": np.arange(naz),
        "rg": np.arange(nrg),
    },
)


dataset = xr.Dataset(
    {"real": real_da, "imag": imag_da}
)
# dataset = xr.Dataset()
# dataset.update()


# # storing lookup tables along with rasters
az_da = xr.DataArray(
    az_p2g,
    dims=("row", "col"),
    coords={"row": np.arange(nl), "col": np.arange(nc)},
    name=f"az_burst_{burst_idx}",
)
rg_da = xr.DataArray(
    rg_p2g,
    dims=("row", "col"),
    coords={"row": np.arange(nl), "col": np.arange(nc)},
    name=f"rg_burst_{burst_idx}",
)

# using a dict because lookuptables can have different shapes
az_da_dict[f"az_burst_{burst_idx}"] = az_da
rg_da_dict[f"rg_burst_{burst_idx}"] = rg_da

dataset["real"].loc[prm.start_time, f"burst_{burst_idx}"] = arr_p.real
dataset["imag"].loc[prm.start_time, f"burst_{burst_idx}"] = arr_p.imag
dataset["real"].loc[sec.start_time, f"burst_{burst_idx}"] = (arr_s2p * pha_topo).real
dataset["imag"].loc[sec.start_time, f"burst_{burst_idx}"] = (arr_s2p * pha_topo).imag

# add LUTs
dataset.update(az_da_dict)    
dataset.update(rg_da_dict)    