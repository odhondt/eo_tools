{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import folium.plugins\n",
    "import logging\n",
    "from json import dumps\n",
    "from eo_tools.util import explore_products\n",
    "\n",
    "from eodag import EODataAccessGateway\n",
    "confpath = \"/data/eodag_config.yml\"\n",
    "dag = EODataAccessGateway(user_conf_file_path=confpath)\n",
    "# make sure cop_dataspace will be used \n",
    "dag.set_preferred_provider(\"cop_dataspace\")\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a geometry\n",
    "file_aoi = \"/data/aoi_Maroc.geojson\"\n",
    "shp = gpd.read_file(file_aoi).geometry[0]\n",
    "search_criteria = {\n",
    "    \"productType\": \"S2_MSI_L1C\",\n",
    "    \"start\": \"2023-04-01\",\n",
    "    \"end\": \"2023-05-30\",\n",
    "    \"geom\": shp\n",
    "}\n",
    "results = dag.search_all(**search_criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_dates(results):\n",
    "    import numpy as np\n",
    "\n",
    "    dates = []\n",
    "    for p in results:\n",
    "        dates.append(p.properties[\"startTimeFromAscendingNode\"])\n",
    "    return np.unique(dates).tolist()\n",
    "\n",
    "dates = get_unique_dates(results)\n",
    "# print(f\"unique dates:\")\n",
    "# print(\", \\n\".join(dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all results\n",
    "# explore_products(results, shp)\n",
    "\n",
    "# filter by date\n",
    "results_20230401 = results.filter_date(\"2023-04-01\", \"2023-04-02\") \n",
    "# explore_products(results_20230401, shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-run to get only links\n",
    "dl = dag.download_all(results_20230401, outputs_prefix=\"/data/S2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# - Convert all to EPSG 4326\n",
    "# - Crop to AOI\n",
    "# - Merge products\n",
    "# - Make GeoTiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TODO: make function and improve descriptions\n",
    "df_bands = pd.DataFrame(\n",
    "    {\n",
    "        \"band\": [\n",
    "            \"B2\",\n",
    "            \"B3\",\n",
    "            \"B4\",\n",
    "            \"B8\",\n",
    "            \"B5\",\n",
    "            \"B6\",\n",
    "            \"B7\",\n",
    "            \"B8A\",\n",
    "            \"B11\",\n",
    "            \"B12\",\n",
    "            \"B1\",\n",
    "            \"B9\",\n",
    "            \"B10\",\n",
    "        ],\n",
    "        \"resolution\": [10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 60, 60, 60],\n",
    "        \"subd\": [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2],\n",
    "        \"idx\": [1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3],\n",
    "        \"description\": [\n",
    "            \"Blue\",\n",
    "            \"Green\",\n",
    "            \"Red\",\n",
    "            \"VNIR\",\n",
    "            \"VNIR\",\n",
    "            \"VNIR\",\n",
    "            \"VNIR\",\n",
    "            \"VNIR\",\n",
    "            \"SWIR\",\n",
    "            \"SWIR\",\n",
    "            \"Coastal\",\n",
    "            \"SWIR\",\n",
    "            \"SWIR\",\n",
    "        ],\n",
    "    }\n",
    ").set_index(\"band\")\n",
    "# df_bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# TODO: add \"all\" options for bands or \"10m\", \"20m\", \"60m\", \"RGB\" + parse single band (not a list)\n",
    "# TODO: AOI prefix\n",
    "# TODO: change prints in logs\n",
    "# TODO: cog\n",
    "def merge_S2_tiles(paths, bands=[\"B4\", \"B3\", \"B2\"], shp=None, outputs_prefix=\"/tmp\"):\n",
    "    import os\n",
    "    from rasterio.warp import reproject, calculate_default_transform\n",
    "    from rasterio.merge import merge\n",
    "    from rasterio import MemoryFile\n",
    "    from rasterio.enums import Resampling\n",
    "    from rasterio import mask\n",
    "    import numpy as np\n",
    "\n",
    "    # identify distinct products\n",
    "    dict_products = {}\n",
    "    for path in paths:\n",
    "        with rasterio.open(path) as ds:\n",
    "            tags = ds.tags()\n",
    "            pid = tags[\"DATATAKE_1_ID\"]\n",
    "            if pid not in dict_products.keys():\n",
    "                dict_products[pid] = [path]\n",
    "            else:\n",
    "                dict_products[pid].append(path)\n",
    "\n",
    "    # merge granules from the same product\n",
    "    for pid, path_list in dict_products.items():\n",
    "        out_dir = f\"{outputs_prefix}/{pid}\"\n",
    "        print(f\"Processing data take {pid}\")\n",
    "        if not os.path.exists(out_dir):\n",
    "            os.mkdir(out_dir)\n",
    "        for band in bands:\n",
    "            print(f\"Band {band}\")\n",
    "            to_merge = []\n",
    "            for path in path_list:\n",
    "                # open granule\n",
    "                with rasterio.open(path) as src:\n",
    "                    print(f\"Tile {path}\")\n",
    "                    row = df_bands.loc[band]\n",
    "                    upscale_factor = int(row[\"resolution\"] / 10)\n",
    "\n",
    "                    # open sub dataset and read band\n",
    "                    with rasterio.open(src.subdatasets[row[\"subd\"]]) as subds:\n",
    "                        prof = subds.profile.copy()\n",
    "                        src_crs = subds.crs\n",
    "\n",
    "                        # upsample to 10m\n",
    "                        if upscale_factor > 1:\n",
    "                            raster = subds.read(\n",
    "                                int(row[\"idx\"]),\n",
    "                                out_shape=(\n",
    "                                    1,\n",
    "                                    int(subds.height * upscale_factor),\n",
    "                                    int(subds.width * upscale_factor),\n",
    "                                ),\n",
    "                                resampling=Resampling.bilinear,\n",
    "                            )\n",
    "                            src_transform = subds.transform * subds.transform.scale(\n",
    "                                (subds.width / raster.shape[-1]),\n",
    "                                (subds.height / raster.shape[-2]),\n",
    "                            )\n",
    "                        else:\n",
    "                            raster = subds.read(int(row[\"idx\"]))\n",
    "                            src_transform = subds.transform\n",
    "\n",
    "                        # calculate transform to reproject\n",
    "                        dst_crs = \"EPSG:4326\"\n",
    "                        transform, width, height = calculate_default_transform(\n",
    "                            subds.crs,\n",
    "                            dst_crs,\n",
    "                            raster.shape[-1],\n",
    "                            raster.shape[-2],\n",
    "                            *subds.bounds,\n",
    "                        )\n",
    "                        prof.update(\n",
    "                            {\n",
    "                                \"crs\": dst_crs,\n",
    "                                \"transform\": transform,\n",
    "                                \"width\": width,\n",
    "                                \"height\": height,\n",
    "                                \"count\": 1,\n",
    "                                \"driver\": \"GTiff\",\n",
    "                                \"compress\": \"deflate\",\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "                    # reproject to EPSG:4326\n",
    "                    with MemoryFile() as memfile:\n",
    "                        with memfile.open(**prof) as tmp_ds:\n",
    "                            reproject(\n",
    "                                source=raster,\n",
    "                                destination=rasterio.band(tmp_ds, 1),\n",
    "                                src_transform=src_transform,\n",
    "                                src_crs=src_crs,\n",
    "                                dst_transform=transform,\n",
    "                                dst_crs=dst_crs,\n",
    "                                resampling=Resampling.bilinear,\n",
    "                            )\n",
    "\n",
    "                            # crop if needed\n",
    "                            if shp is not None:\n",
    "                                raster, transform = mask.mask(tmp_ds, [shp], crop=True)\n",
    "                                prof.update(\n",
    "                                    {\n",
    "                                        \"width\": raster.shape[-1],\n",
    "                                        \"height\": raster.shape[-2],\n",
    "                                        \"transform\": transform,\n",
    "                                    }\n",
    "                                )\n",
    "                            else:\n",
    "                                raster = tmp_ds.read()\n",
    "                    # Hardcoded quantification\n",
    "                    # TODO: apply bias correction for processor > 4\n",
    "                    raster = raster.astype(np.float32) / 10000\n",
    "                    prof.update(\n",
    "                        {\n",
    "                            \"dtype\": \"float32\",\n",
    "                        }\n",
    "                    )\n",
    "                    # create dataset to merge\n",
    "                    memfile = MemoryFile()\n",
    "                    tmp_ds = memfile.open(**prof)\n",
    "                    tmp_ds.write(raster)\n",
    "\n",
    "                    # add to merge list\n",
    "                    to_merge.append(tmp_ds)\n",
    "\n",
    "            print(f\"Merging {len(to_merge)} tiles\")\n",
    "            arr_merge, trans_merge = merge(to_merge)\n",
    "            for ds in to_merge:\n",
    "                ds.close()\n",
    "            prof.update(\n",
    "                {\n",
    "                    \"height\": arr_merge.shape[1],\n",
    "                    \"width\": arr_merge.shape[2],\n",
    "                    \"transform\": trans_merge,\n",
    "                    \"nodata\": 0,\n",
    "                }\n",
    "            )\n",
    "            # TODO: optional stacking?\n",
    "            with rasterio.open(f\"{out_dir}/{band}.tif\", \"w\", **prof) as dst:\n",
    "                dst.write(arr_merge)\n",
    "\n",
    "\n",
    "# merge_S2_tiles(dl, shp=shp, bands=['B2', 'B11', 'B10'], outputs_prefix=\"/data/res/\")\n",
    "merge_S2_tiles(dl, bands=[\"B2\"],shp=shp, outputs_prefix=\"/data/res/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from pprint import pprint\n",
    "with rasterio.open(dl[0]) as ds:\n",
    "    with rasterio.open(ds.subdatasets[0]) as ds0:\n",
    "        pprint(ds0.tag_namespaces())\n",
    "        pprint(ds0.tags(ns='xml:SENTINEL2'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rasterio.mask.mask?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geojson\n",
    "# import json\n",
    "# gpd.read_file(json.dumps(results.as_geojson_object()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
